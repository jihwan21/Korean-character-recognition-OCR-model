{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfddfcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_files_in_folder(folder_path):\n",
    "    try:\n",
    "        files = os.listdir(folder_path)\n",
    "\n",
    "        file_count = 0\n",
    "\n",
    "        for file in files:\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                file_count += 1\n",
    "\n",
    "        print(f\"폴더 '{folder_path}' 안에 {file_count}개의 파일이 있습니다.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"폴더 '{folder_path}' not defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3bad18",
   "metadata": {},
   "source": [
    "# Data reading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be9e03b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'images', 'annotations', 'licenses'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Text in the wild Dataset', 'date_created': '2019-10-14 04:31:48'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file = json.load(open('data/textinthewild_data_info.json'))\n",
    "display(file.keys(), file['info'] , type(file['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edbc54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "#ocr_book_files = os.listdir('data/01_textinthewild_book_images_new/book')\n",
    "ocr_good_files = os.listdir('data/01_textinthewild_goods_images_new/Goods')\n",
    "#ocr_sign_files = os.listdir('data/01_textinthewild_signboard_images_new/Signboard')\n",
    "#ocr_traf_files = os.listdir('data/01_textinthewild_traffic_sign_images_new/traffic_sign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8920700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocr_files - 사진 파일 이름 저장  \n",
    "ocr_files =  ocr_good_files #+ ocr_sign_files  + ocr_traf_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c930423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18440 3951 3951\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random.shuffle(ocr_files)\n",
    "\n",
    "n_train = int(len(ocr_files) * 0.7) \n",
    "n_validation = int(len(ocr_files) * 0.15) \n",
    "n_test = int(len(ocr_files) * 0.15)\n",
    "\n",
    "print(n_train, n_validation, n_test)  \n",
    "\n",
    "train_files = ocr_files[:n_train]\n",
    "validation_files = ocr_files[n_train: n_train+n_validation]\n",
    "test_files = ocr_files[-n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ce05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train/validation/test 이미지들에 해당하는 id 값을 저장\n",
    "# 이때 id 값은 json 파일에서 가져온 것임 \n",
    "# 해당 id 값들을 train,test,val 에 맞게 spliting 한 것임 \n",
    "\n",
    "train_img_ids = {}\n",
    "validation_img_ids = {}\n",
    "test_img_ids = {}\n",
    "\n",
    "for image in file['images']:\n",
    "    if image['file_name'] in train_files:\n",
    "        train_img_ids[image['file_name']] = image['id']\n",
    "        \n",
    "    elif image['file_name'] in validation_files:\n",
    "        validation_img_ids[image['file_name']] = image['id']\n",
    "        \n",
    "    elif image['file_name'] in test_files:\n",
    "        test_img_ids[image['file_name']] = image['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3095e06b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18440"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(train_img_ids),len(validation_img_ids),len(test_img_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bee4a07",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 2096460 processed\n",
      "5000 / 2096460 processed\n",
      "10000 / 2096460 processed\n",
      "15000 / 2096460 processed\n",
      "20000 / 2096460 processed\n",
      "25000 / 2096460 processed\n",
      "30000 / 2096460 processed\n",
      "35000 / 2096460 processed\n",
      "40000 / 2096460 processed\n",
      "45000 / 2096460 processed\n",
      "50000 / 2096460 processed\n",
      "55000 / 2096460 processed\n",
      "60000 / 2096460 processed\n",
      "65000 / 2096460 processed\n",
      "70000 / 2096460 processed\n",
      "75000 / 2096460 processed\n",
      "80000 / 2096460 processed\n",
      "85000 / 2096460 processed\n",
      "90000 / 2096460 processed\n",
      "95000 / 2096460 processed\n",
      "100000 / 2096460 processed\n",
      "105000 / 2096460 processed\n",
      "110000 / 2096460 processed\n",
      "115000 / 2096460 processed\n",
      "120000 / 2096460 processed\n",
      "125000 / 2096460 processed\n",
      "130000 / 2096460 processed\n",
      "135000 / 2096460 processed\n",
      "140000 / 2096460 processed\n",
      "145000 / 2096460 processed\n",
      "150000 / 2096460 processed\n",
      "155000 / 2096460 processed\n",
      "160000 / 2096460 processed\n",
      "165000 / 2096460 processed\n",
      "170000 / 2096460 processed\n",
      "175000 / 2096460 processed\n",
      "180000 / 2096460 processed\n",
      "185000 / 2096460 processed\n",
      "190000 / 2096460 processed\n",
      "195000 / 2096460 processed\n",
      "200000 / 2096460 processed\n",
      "205000 / 2096460 processed\n",
      "210000 / 2096460 processed\n",
      "215000 / 2096460 processed\n",
      "220000 / 2096460 processed\n",
      "225000 / 2096460 processed\n",
      "230000 / 2096460 processed\n",
      "235000 / 2096460 processed\n",
      "240000 / 2096460 processed\n",
      "245000 / 2096460 processed\n",
      "250000 / 2096460 processed\n",
      "255000 / 2096460 processed\n",
      "260000 / 2096460 processed\n",
      "265000 / 2096460 processed\n",
      "270000 / 2096460 processed\n",
      "275000 / 2096460 processed\n",
      "280000 / 2096460 processed\n",
      "285000 / 2096460 processed\n",
      "290000 / 2096460 processed\n",
      "295000 / 2096460 processed\n",
      "300000 / 2096460 processed\n",
      "305000 / 2096460 processed\n",
      "310000 / 2096460 processed\n",
      "315000 / 2096460 processed\n",
      "320000 / 2096460 processed\n",
      "325000 / 2096460 processed\n",
      "330000 / 2096460 processed\n",
      "335000 / 2096460 processed\n",
      "340000 / 2096460 processed\n",
      "345000 / 2096460 processed\n",
      "350000 / 2096460 processed\n",
      "355000 / 2096460 processed\n",
      "360000 / 2096460 processed\n",
      "365000 / 2096460 processed\n",
      "370000 / 2096460 processed\n",
      "375000 / 2096460 processed\n",
      "380000 / 2096460 processed\n",
      "385000 / 2096460 processed\n",
      "390000 / 2096460 processed\n",
      "395000 / 2096460 processed\n",
      "400000 / 2096460 processed\n",
      "405000 / 2096460 processed\n",
      "410000 / 2096460 processed\n",
      "415000 / 2096460 processed\n",
      "420000 / 2096460 processed\n",
      "425000 / 2096460 processed\n",
      "430000 / 2096460 processed\n",
      "435000 / 2096460 processed\n",
      "440000 / 2096460 processed\n",
      "445000 / 2096460 processed\n",
      "450000 / 2096460 processed\n",
      "455000 / 2096460 processed\n",
      "460000 / 2096460 processed\n",
      "465000 / 2096460 processed\n",
      "470000 / 2096460 processed\n",
      "475000 / 2096460 processed\n",
      "480000 / 2096460 processed\n",
      "485000 / 2096460 processed\n",
      "490000 / 2096460 processed\n",
      "495000 / 2096460 processed\n",
      "500000 / 2096460 processed\n",
      "505000 / 2096460 processed\n",
      "510000 / 2096460 processed\n",
      "515000 / 2096460 processed\n",
      "520000 / 2096460 processed\n",
      "525000 / 2096460 processed\n",
      "530000 / 2096460 processed\n",
      "535000 / 2096460 processed\n",
      "540000 / 2096460 processed\n",
      "545000 / 2096460 processed\n",
      "550000 / 2096460 processed\n",
      "555000 / 2096460 processed\n",
      "560000 / 2096460 processed\n",
      "565000 / 2096460 processed\n",
      "570000 / 2096460 processed\n",
      "575000 / 2096460 processed\n",
      "580000 / 2096460 processed\n",
      "585000 / 2096460 processed\n",
      "590000 / 2096460 processed\n",
      "595000 / 2096460 processed\n",
      "600000 / 2096460 processed\n",
      "605000 / 2096460 processed\n",
      "610000 / 2096460 processed\n",
      "615000 / 2096460 processed\n",
      "620000 / 2096460 processed\n",
      "625000 / 2096460 processed\n",
      "630000 / 2096460 processed\n",
      "635000 / 2096460 processed\n",
      "640000 / 2096460 processed\n",
      "645000 / 2096460 processed\n",
      "650000 / 2096460 processed\n",
      "655000 / 2096460 processed\n",
      "660000 / 2096460 processed\n",
      "665000 / 2096460 processed\n",
      "670000 / 2096460 processed\n",
      "675000 / 2096460 processed\n",
      "680000 / 2096460 processed\n",
      "685000 / 2096460 processed\n",
      "690000 / 2096460 processed\n",
      "695000 / 2096460 processed\n",
      "700000 / 2096460 processed\n",
      "705000 / 2096460 processed\n",
      "710000 / 2096460 processed\n",
      "715000 / 2096460 processed\n",
      "720000 / 2096460 processed\n",
      "725000 / 2096460 processed\n",
      "730000 / 2096460 processed\n",
      "735000 / 2096460 processed\n",
      "740000 / 2096460 processed\n",
      "745000 / 2096460 processed\n",
      "750000 / 2096460 processed\n",
      "755000 / 2096460 processed\n",
      "760000 / 2096460 processed\n",
      "765000 / 2096460 processed\n",
      "770000 / 2096460 processed\n",
      "775000 / 2096460 processed\n",
      "780000 / 2096460 processed\n",
      "785000 / 2096460 processed\n",
      "790000 / 2096460 processed\n",
      "795000 / 2096460 processed\n",
      "800000 / 2096460 processed\n",
      "805000 / 2096460 processed\n",
      "810000 / 2096460 processed\n",
      "815000 / 2096460 processed\n",
      "820000 / 2096460 processed\n",
      "825000 / 2096460 processed\n",
      "830000 / 2096460 processed\n",
      "835000 / 2096460 processed\n",
      "840000 / 2096460 processed\n",
      "845000 / 2096460 processed\n",
      "850000 / 2096460 processed\n",
      "855000 / 2096460 processed\n",
      "860000 / 2096460 processed\n",
      "865000 / 2096460 processed\n",
      "870000 / 2096460 processed\n",
      "875000 / 2096460 processed\n",
      "880000 / 2096460 processed\n",
      "885000 / 2096460 processed\n",
      "890000 / 2096460 processed\n",
      "895000 / 2096460 processed\n",
      "900000 / 2096460 processed\n",
      "905000 / 2096460 processed\n",
      "910000 / 2096460 processed\n",
      "915000 / 2096460 processed\n",
      "920000 / 2096460 processed\n",
      "925000 / 2096460 processed\n",
      "930000 / 2096460 processed\n",
      "935000 / 2096460 processed\n",
      "940000 / 2096460 processed\n",
      "945000 / 2096460 processed\n",
      "950000 / 2096460 processed\n",
      "955000 / 2096460 processed\n",
      "960000 / 2096460 processed\n",
      "965000 / 2096460 processed\n",
      "970000 / 2096460 processed\n",
      "975000 / 2096460 processed\n",
      "980000 / 2096460 processed\n",
      "985000 / 2096460 processed\n",
      "990000 / 2096460 processed\n",
      "995000 / 2096460 processed\n",
      "1000000 / 2096460 processed\n",
      "1005000 / 2096460 processed\n",
      "1010000 / 2096460 processed\n",
      "1015000 / 2096460 processed\n",
      "1020000 / 2096460 processed\n",
      "1025000 / 2096460 processed\n",
      "1030000 / 2096460 processed\n",
      "1035000 / 2096460 processed\n",
      "1040000 / 2096460 processed\n",
      "1045000 / 2096460 processed\n",
      "1050000 / 2096460 processed\n",
      "1055000 / 2096460 processed\n",
      "1060000 / 2096460 processed\n",
      "1065000 / 2096460 processed\n",
      "1070000 / 2096460 processed\n",
      "1075000 / 2096460 processed\n",
      "1080000 / 2096460 processed\n",
      "1085000 / 2096460 processed\n",
      "1090000 / 2096460 processed\n",
      "1095000 / 2096460 processed\n",
      "1100000 / 2096460 processed\n",
      "1105000 / 2096460 processed\n",
      "1110000 / 2096460 processed\n",
      "1115000 / 2096460 processed\n",
      "1120000 / 2096460 processed\n",
      "1125000 / 2096460 processed\n",
      "1130000 / 2096460 processed\n",
      "1135000 / 2096460 processed\n",
      "1140000 / 2096460 processed\n",
      "1145000 / 2096460 processed\n",
      "1150000 / 2096460 processed\n",
      "1155000 / 2096460 processed\n",
      "1160000 / 2096460 processed\n",
      "1165000 / 2096460 processed\n",
      "1170000 / 2096460 processed\n",
      "1175000 / 2096460 processed\n",
      "1180000 / 2096460 processed\n",
      "1185000 / 2096460 processed\n",
      "1190000 / 2096460 processed\n",
      "1195000 / 2096460 processed\n",
      "1200000 / 2096460 processed\n",
      "1205000 / 2096460 processed\n",
      "1210000 / 2096460 processed\n",
      "1215000 / 2096460 processed\n",
      "1220000 / 2096460 processed\n",
      "1225000 / 2096460 processed\n",
      "1230000 / 2096460 processed\n",
      "1235000 / 2096460 processed\n",
      "1240000 / 2096460 processed\n",
      "1245000 / 2096460 processed\n",
      "1250000 / 2096460 processed\n",
      "1255000 / 2096460 processed\n",
      "1260000 / 2096460 processed\n",
      "1265000 / 2096460 processed\n",
      "1270000 / 2096460 processed\n",
      "1275000 / 2096460 processed\n",
      "1280000 / 2096460 processed\n",
      "1285000 / 2096460 processed\n",
      "1290000 / 2096460 processed\n",
      "1295000 / 2096460 processed\n",
      "1300000 / 2096460 processed\n",
      "1305000 / 2096460 processed\n",
      "1310000 / 2096460 processed\n",
      "1315000 / 2096460 processed\n",
      "1320000 / 2096460 processed\n",
      "1325000 / 2096460 processed\n",
      "1330000 / 2096460 processed\n",
      "1335000 / 2096460 processed\n",
      "1340000 / 2096460 processed\n",
      "1345000 / 2096460 processed\n",
      "1350000 / 2096460 processed\n",
      "1355000 / 2096460 processed\n",
      "1360000 / 2096460 processed\n",
      "1365000 / 2096460 processed\n",
      "1370000 / 2096460 processed\n",
      "1375000 / 2096460 processed\n",
      "1380000 / 2096460 processed\n",
      "1385000 / 2096460 processed\n",
      "1390000 / 2096460 processed\n",
      "1395000 / 2096460 processed\n",
      "1400000 / 2096460 processed\n",
      "1405000 / 2096460 processed\n",
      "1410000 / 2096460 processed\n",
      "1415000 / 2096460 processed\n",
      "1420000 / 2096460 processed\n",
      "1425000 / 2096460 processed\n",
      "1430000 / 2096460 processed\n",
      "1435000 / 2096460 processed\n",
      "1440000 / 2096460 processed\n",
      "1445000 / 2096460 processed\n",
      "1450000 / 2096460 processed\n",
      "1455000 / 2096460 processed\n",
      "1460000 / 2096460 processed\n",
      "1465000 / 2096460 processed\n",
      "1470000 / 2096460 processed\n",
      "1475000 / 2096460 processed\n",
      "1480000 / 2096460 processed\n",
      "1485000 / 2096460 processed\n",
      "1490000 / 2096460 processed\n",
      "1495000 / 2096460 processed\n",
      "1500000 / 2096460 processed\n",
      "1505000 / 2096460 processed\n",
      "1510000 / 2096460 processed\n",
      "1515000 / 2096460 processed\n",
      "1520000 / 2096460 processed\n",
      "1525000 / 2096460 processed\n",
      "1530000 / 2096460 processed\n",
      "1535000 / 2096460 processed\n",
      "1540000 / 2096460 processed\n",
      "1545000 / 2096460 processed\n",
      "1550000 / 2096460 processed\n",
      "1555000 / 2096460 processed\n",
      "1560000 / 2096460 processed\n",
      "1565000 / 2096460 processed\n",
      "1570000 / 2096460 processed\n",
      "1575000 / 2096460 processed\n",
      "1580000 / 2096460 processed\n",
      "1585000 / 2096460 processed\n",
      "1590000 / 2096460 processed\n",
      "1595000 / 2096460 processed\n",
      "1600000 / 2096460 processed\n",
      "1605000 / 2096460 processed\n",
      "1610000 / 2096460 processed\n",
      "1615000 / 2096460 processed\n",
      "1620000 / 2096460 processed\n",
      "1625000 / 2096460 processed\n",
      "1630000 / 2096460 processed\n",
      "1635000 / 2096460 processed\n",
      "1640000 / 2096460 processed\n",
      "1645000 / 2096460 processed\n",
      "1650000 / 2096460 processed\n",
      "1655000 / 2096460 processed\n",
      "1660000 / 2096460 processed\n",
      "1665000 / 2096460 processed\n",
      "1670000 / 2096460 processed\n",
      "1675000 / 2096460 processed\n",
      "1680000 / 2096460 processed\n",
      "1685000 / 2096460 processed\n",
      "1690000 / 2096460 processed\n",
      "1695000 / 2096460 processed\n",
      "1700000 / 2096460 processed\n",
      "1705000 / 2096460 processed\n",
      "1710000 / 2096460 processed\n",
      "1715000 / 2096460 processed\n",
      "1720000 / 2096460 processed\n",
      "1725000 / 2096460 processed\n",
      "1730000 / 2096460 processed\n",
      "1735000 / 2096460 processed\n",
      "1740000 / 2096460 processed\n",
      "1745000 / 2096460 processed\n",
      "1750000 / 2096460 processed\n",
      "1755000 / 2096460 processed\n",
      "1760000 / 2096460 processed\n",
      "1765000 / 2096460 processed\n",
      "1770000 / 2096460 processed\n",
      "1775000 / 2096460 processed\n",
      "1780000 / 2096460 processed\n",
      "1785000 / 2096460 processed\n",
      "1790000 / 2096460 processed\n",
      "1795000 / 2096460 processed\n",
      "1800000 / 2096460 processed\n",
      "1805000 / 2096460 processed\n",
      "1810000 / 2096460 processed\n",
      "1815000 / 2096460 processed\n",
      "1820000 / 2096460 processed\n",
      "1825000 / 2096460 processed\n",
      "1830000 / 2096460 processed\n",
      "1835000 / 2096460 processed\n",
      "1840000 / 2096460 processed\n",
      "1845000 / 2096460 processed\n",
      "1850000 / 2096460 processed\n",
      "1855000 / 2096460 processed\n",
      "1860000 / 2096460 processed\n",
      "1865000 / 2096460 processed\n",
      "1870000 / 2096460 processed\n",
      "1875000 / 2096460 processed\n",
      "1880000 / 2096460 processed\n",
      "1885000 / 2096460 processed\n",
      "1890000 / 2096460 processed\n",
      "1895000 / 2096460 processed\n",
      "1900000 / 2096460 processed\n",
      "1905000 / 2096460 processed\n",
      "1910000 / 2096460 processed\n",
      "1915000 / 2096460 processed\n",
      "1920000 / 2096460 processed\n",
      "1925000 / 2096460 processed\n",
      "1930000 / 2096460 processed\n",
      "1935000 / 2096460 processed\n",
      "1940000 / 2096460 processed\n",
      "1945000 / 2096460 processed\n",
      "1950000 / 2096460 processed\n",
      "1955000 / 2096460 processed\n",
      "1960000 / 2096460 processed\n",
      "1965000 / 2096460 processed\n",
      "1970000 / 2096460 processed\n",
      "1975000 / 2096460 processed\n",
      "1980000 / 2096460 processed\n",
      "1985000 / 2096460 processed\n",
      "1990000 / 2096460 processed\n",
      "1995000 / 2096460 processed\n",
      "2000000 / 2096460 processed\n",
      "2005000 / 2096460 processed\n",
      "2010000 / 2096460 processed\n",
      "2015000 / 2096460 processed\n",
      "2020000 / 2096460 processed\n",
      "2025000 / 2096460 processed\n",
      "2030000 / 2096460 processed\n",
      "2035000 / 2096460 processed\n",
      "2040000 / 2096460 processed\n",
      "2045000 / 2096460 processed\n",
      "2050000 / 2096460 processed\n",
      "2055000 / 2096460 processed\n",
      "2060000 / 2096460 processed\n",
      "2065000 / 2096460 processed\n",
      "2070000 / 2096460 processed\n",
      "2075000 / 2096460 processed\n",
      "2080000 / 2096460 processed\n",
      "2085000 / 2096460 processed\n",
      "2090000 / 2096460 processed\n",
      "2095000 / 2096460 processed\n"
     ]
    }
   ],
   "source": [
    "## train/validation/test 이미지들에 해당하는 annotation 들을 저장\n",
    "\n",
    "train_annotations = {f:[] for f in train_img_ids.keys()} #keys -> 파일 이름  # 파일이름 : [] 로 value 가 비어있는 딕셔내리 형성 \n",
    "validation_annotations = {f:[] for f in validation_img_ids.keys()}\n",
    "test_annotations = {f:[] for f in test_img_ids.keys()}\n",
    "\n",
    "train_ids_img = {train_img_ids[id_]:id_ for id_ in train_img_ids}  # id : 해당 파일 이름 -> 으로 구성된 딕셔내리 \n",
    "validation_ids_img = {validation_img_ids[id_]:id_ for id_ in validation_img_ids} \n",
    "test_ids_img = {test_img_ids[id_]:id_ for id_ in test_img_ids}\n",
    "\n",
    "for idx, annotation in enumerate(file['annotations']):\n",
    "    if idx % 5000 == 0:\n",
    "        print(idx,'/',len(file['annotations']),'processed')\n",
    "    if annotation['attributes']['class'] != 'word': # class 가 word 가 아니면, 아래 반복문 실행 X \n",
    "        continue\n",
    "    if annotation['image_id'] in train_ids_img:\n",
    "        train_annotations[train_ids_img[annotation['image_id']]].append(annotation)\n",
    "    elif annotation['image_id'] in validation_ids_img:\n",
    "        validation_annotations[validation_ids_img[annotation['image_id']]].append(annotation)\n",
    "    elif annotation['image_id'] in test_ids_img:\n",
    "        test_annotations[test_ids_img[annotation['image_id']]].append(annotation)\n",
    "\n",
    "with open('train_annotation.json', 'w') as file:\n",
    "    json.dump(train_annotations, file)\n",
    "with open('validation_annotation.json', 'w') as file:\n",
    "    json.dump(validation_annotations, file)\n",
    "with open('test_annotation.json', 'w') as file:\n",
    "    json.dump(test_annotations, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a6129e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d156317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3951/3951 [02:52<00:00, 22.86it/s]\n"
     ]
    }
   ],
   "source": [
    "## aihub 데이터 annotation을 읽어서 단어 단위로 잘라서 data에 저장하기\n",
    "\n",
    "data_root_path = 'data/ocr_solut/'\n",
    "save_root_path = 'deep-text-recognition-benchmark/data/'\n",
    "\n",
    "# test \n",
    "test_annotations = json.load(open('./test_annotation.json'))\n",
    "gt_file = open(save_root_path+'gt_test.txt', 'w')\n",
    "\n",
    "\n",
    "for file_name in tqdm(test_annotations):\n",
    "    annotations = test_annotations[file_name]\n",
    "    image = cv2.imread(data_root_path+file_name)\n",
    "    for idx, annotation in enumerate(annotations):\n",
    "        x,y,w,h = annotation['bbox']\n",
    "        if x<= 0 or y<= 0 or w <= 0 or h <= 0:\n",
    "            continue\n",
    "        text = annotation['text']\n",
    "        crop_img = image[y:y+h,x:x+w]\n",
    "        crop_file_name = file_name[:-4]+'_{:03}.jpg'.format(idx+1)\n",
    "        cv2.imwrite(save_root_path+'test/'+crop_file_name, crop_img)\n",
    "        gt_file.write(\"test/{}\\t{}\\n\".format(crop_file_name, text))\n",
    "\n",
    "# Close the file after writing\n",
    "gt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c643d2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 'deep-text-recognition-benchmark/data/test' 안에 11810개의 파일이 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# img 수 \n",
    "count_files_in_folder(save_root_path+'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0336bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 11810 lines.\n"
     ]
    }
   ],
   "source": [
    "#txt file 길이 \n",
    "with open(save_root_path+'gt_test.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    num_lines = len(lines)\n",
    "    #print(content)\n",
    "    print(f'The file contains {num_lines} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d052f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3951/3951 [03:01<00:00, 21.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# validation \n",
    "validation_annotations = json.load(open('./validation_annotation.json'))\n",
    "gt_file = open(save_root_path+'gt_validation.txt', 'w')\n",
    "\n",
    "for file_name in tqdm(validation_annotations):\n",
    "    annotations = validation_annotations[file_name]\n",
    "    image = cv2.imread(data_root_path+file_name)\n",
    "    for idx, annotation in enumerate(annotations):\n",
    "        x,y,w,h = annotation['bbox']\n",
    "        if x<= 0 or y<= 0 or w <= 0 or h <= 0:\n",
    "            continue        \n",
    "        text = annotation['text']\n",
    "        crop_img = image[y:y+h,x:x+w]\n",
    "        crop_file_name = file_name[:-4]+'_{:03}.jpg'.format(idx+1)\n",
    "        cv2.imwrite(save_root_path+'validation/'+crop_file_name, crop_img)\n",
    "        gt_file.write(\"validation/{}\\t{}\\n\".format(crop_file_name, text))\n",
    "\n",
    "# Close the file after writing\n",
    "gt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "123df96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 'deep-text-recognition-benchmark/data/validation' 안에 11929개의 파일이 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# img 수 \n",
    "count_files_in_folder(save_root_path+'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f9b56a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 11929 lines.\n"
     ]
    }
   ],
   "source": [
    "#txt file 길이 \n",
    "with open(save_root_path+'gt_validation.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    num_lines = len(lines)\n",
    "    #print(content)\n",
    "    print(f'The file contains {num_lines} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "135d8022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 18440/18440 [14:03<00:00, 21.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "train_annotations = json.load(open('./train_annotation.json'))\n",
    "gt_file = open(save_root_path+'gt_train.txt', 'w')\n",
    "\n",
    "\n",
    "for file_name in tqdm(train_annotations):\n",
    "    annotations = train_annotations[file_name]\n",
    "    image = cv2.imread(data_root_path + file_name)\n",
    "\n",
    "    if image is None or image.size == 0:\n",
    "        # Skip processing empty images\n",
    "        continue\n",
    "\n",
    "    for idx, annotation in enumerate(annotations):\n",
    "        x, y, w, h = annotation['bbox']\n",
    "        if x <= 0 or y <= 0 or w <= 0 or h <= 0:\n",
    "            continue\n",
    "\n",
    "        text = annotation['text']\n",
    "        crop_img = image[y:y + h, x:x + w]\n",
    "\n",
    "        if crop_img.size == 0:\n",
    "            # Skip processing empty cropped images\n",
    "            continue\n",
    "\n",
    "        crop_file_name = file_name[:-4] + '_{:03}.jpg'.format(idx + 1)\n",
    "        cv2.imwrite(save_root_path + 'train/' + crop_file_name, crop_img)\n",
    "        gt_file.write(\"train/{}\\t{}\\n\".format(crop_file_name, text))\n",
    "\n",
    "gt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13a089d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 'deep-text-recognition-benchmark/data/train' 안에 55443개의 파일이 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# img 수 \n",
    "count_files_in_folder(save_root_path+'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c4c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 55443 lines.\n"
     ]
    }
   ],
   "source": [
    "#txt file 길이 \n",
    "with open(save_root_path+'gt_train.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    num_lines = len(lines)\n",
    "    #print(content)\n",
    "    print(f'The file contains {num_lines} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a97dcf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation -> val \n",
    "\n",
    "file_path = 'deep-text-recognition-benchmark/data/gt_validation.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# \"validation\"을 \"val\"로 바꾸기\n",
    "new_content = content.replace('validation', 'val')\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(new_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
